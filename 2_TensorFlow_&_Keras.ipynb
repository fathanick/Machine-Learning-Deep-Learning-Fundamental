{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_TensorFlow_&_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fathanick/Machine-Learning-Deep-Learning-Fundamental/blob/master/2_TensorFlow_%26_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8qFfS5mBv5c",
        "colab_type": "text"
      },
      "source": [
        "# Deep Learning Framework Introduction (TensorFlow & Keras)\n",
        "\n",
        "Pada dasarnya untuk melakukan training pada neural network, kita melakukan proses pada diagram dibawah ini secara terus menerus hingga loss atau error yang didapatkan memiliki nilai yang relatif kecil.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/894/1*bsjmNlxtISCrsYg1Jy7X3g.jpeg)\n",
        "\n",
        "Namun, jika masalah yang akan kita selesaikan itu adalah permasalahan yang sangat kompleks, atau mungkin kita membutuhkan arsitektur yang unik dan kompleks, atau kita membutuhkan processing unit yang handal untuk mempercepat proses training data, seperti menggunakan GPU. \n",
        "\n",
        "Semua hal diatas dapat diatasi dengan menggunakan sebuah framework. Sama halnya seperti semua framework, deep learning framework ada untuk memudahkan kita untuk menyelesaikan masalah menggunakan deep learning.\n",
        "\n",
        "Sebenarnya ada banyak sekali framework untuk deep learning. \n",
        "Contoh Google mempunyai TensorFlow, Facebook dengan Caffe2, Microsoft dengan CNTK dan masih banyak lagi framework lain seperti Theano dan PyTorch. Kali ini yang akan kita coba sama-sama yaitu TensorFlow (TF)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFKHExwGFA6C",
        "colab_type": "text"
      },
      "source": [
        "# Keras\n",
        "\n",
        "TensorFlow sebenarnya sudah cukup jelas cara penggunaannya, tapi kadang dalam riset seringkali dibutuhkan untuk mencoba arsitektur lain, mencari optimizer yang paling cepat dan bagus, tweaking hyperparameter, dll. Sehingga dibutuhkan package tambahan, seperti **Keras**.\n",
        "\n",
        "Keras sebenarnya adalah wrapper dari TensorFlow untuk lebih memudahkan pengguna dalam mengolah data dengan Deep Learning. Selain TensorFlow, Keras juga dapat digunakan untuk framework Theano dan CNTK.\n",
        "\n",
        "![alt text](https://miro.medium.com/max/500/1*VqUWF8HP-v2Z4myobSBcSA.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gf-pHtzNJMgC",
        "colab_type": "text"
      },
      "source": [
        "# Non Linier Regression dengan framework Tensor Flow dan Keras\n",
        "\n",
        "Misal akan dilakukan regresi terhadap sebuah fungsi non-linear seperti berikut:\n",
        "\n",
        "![alt text](https://miro.medium.com/max/287/1*w-qEWrqSw6REdmrE6_d1wQ.jpeg)\n",
        "\n",
        "kita akan membuat data dengan menggunakan numpy. Input datanya dari rentang -20 sampai 20 dengan step 0.25. Kita juga buat targetnya sesuai dengan persamaan diatas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYODBSgyLq0A",
        "colab_type": "code",
        "outputId": "562ba974-40ef-4a07-905b-4001f233dbdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Activation, Dense\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "# Generate data from -20, -19.75, -19.5, .... , 20\n",
        "train_x = np.arange(-20, 20, 0.25)\n",
        "\n",
        "# Calculate Target : sqrt(2x^2 + 1)\n",
        "train_y = np.sqrt((2*train_x**2)+1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2459Y7I5McGL",
        "colab_type": "text"
      },
      "source": [
        "Sedangkan arsitektur neural networknya terdiri dari:\n",
        "*   1 node pada input layer\n",
        "*   8 node pada Hidden Layer 1 dengan ReLU activation\n",
        "*   4 node pada Hidden Layer 2 dengan ReLU activation\n",
        "*   1 Output node dengan Linear activation\n",
        "\n",
        "Di sini optimizer yang akan kita gunakan adalah SGD dan Mean Squared Error (MSE) sebagai loss functionnya. \n",
        "Sebelum kita bisa melakukan training, kita harus meng-”compile” model kita terlebih dahulu.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfBXqDsDNPG8",
        "colab_type": "code",
        "outputId": "ec89ca09-3756-4ea7-be7a-21714b03df9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "# Create Network\n",
        "inputs = Input(shape=(1,))\n",
        "h_layer = Dense(8, activation='relu')(inputs)\n",
        "h_layer = Dense(4, activation='relu')(h_layer)\n",
        "outputs = Dense(1, activation='linear')(h_layer)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Optimizer / Update Rule\n",
        "sgd = SGD(lr=0.001)\n",
        "# Compile the model with Mean Squared Error Loss\n",
        "model.compile(optimizer=sgd, loss='mse')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W1110 03:13:18.567272 140483142891392 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W1110 03:13:18.580785 140483142891392 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W1110 03:13:18.590420 140483142891392 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W1110 03:13:18.638962 140483142891392 module_wrapper.py:139] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZA01PgAtN8WX",
        "colab_type": "text"
      },
      "source": [
        "Setelah model siap, akan dilakukan data training berdasarkan input yang telah dimasukkan. Untuk melakukan training, kita harus memanggil method fit. Pada method ini ada param batch_size dengan nilai 20 yang artinya kita gunakan mini-batch SGD.\n",
        "\n",
        "Kita akan lakukan ini hingga 10000 epoch dan menyimpan semua parameter (weights dan bias) kedalam sebuah file.\n",
        "Epoch, learning rate, batch_size, dll ini adalah hyperparameter yang bisa kita tentukan. Setelah epochs 1000, berapakah MSE yang Anda peroleh?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJpDBn0dPfLU",
        "colab_type": "code",
        "outputId": "82110bed-e0f5-49a6-e475-afbe76cd7804",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Train the network and save the weights after training\n",
        "model.fit(train_x, train_y, batch_size=20, epochs=1000, verbose=1)\n",
        "model.save_weights('weights.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "160/160 [==============================] - 0s 117us/step - loss: 0.0040\n",
            "Epoch 2/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0047\n",
            "Epoch 3/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0057\n",
            "Epoch 4/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0060\n",
            "Epoch 5/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0075\n",
            "Epoch 6/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0057\n",
            "Epoch 7/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0057\n",
            "Epoch 8/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0057\n",
            "Epoch 9/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0038\n",
            "Epoch 10/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0038\n",
            "Epoch 11/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0083\n",
            "Epoch 12/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0081\n",
            "Epoch 13/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0178\n",
            "Epoch 14/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0038\n",
            "Epoch 15/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0036\n",
            "Epoch 16/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0039\n",
            "Epoch 17/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0061\n",
            "Epoch 18/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0042\n",
            "Epoch 19/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0040\n",
            "Epoch 20/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0045\n",
            "Epoch 21/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0037\n",
            "Epoch 22/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0040\n",
            "Epoch 23/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0044\n",
            "Epoch 24/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0049\n",
            "Epoch 25/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0064\n",
            "Epoch 26/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0099\n",
            "Epoch 27/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0069\n",
            "Epoch 28/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0038\n",
            "Epoch 29/1000\n",
            "160/160 [==============================] - 0s 97us/step - loss: 0.0039\n",
            "Epoch 30/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0041\n",
            "Epoch 31/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0038\n",
            "Epoch 32/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0036\n",
            "Epoch 33/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0038\n",
            "Epoch 34/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0037\n",
            "Epoch 35/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0038\n",
            "Epoch 36/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0046\n",
            "Epoch 37/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0048\n",
            "Epoch 38/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0039\n",
            "Epoch 39/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0043\n",
            "Epoch 40/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0046\n",
            "Epoch 41/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0039\n",
            "Epoch 42/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0041\n",
            "Epoch 43/1000\n",
            "160/160 [==============================] - 0s 99us/step - loss: 0.0097\n",
            "Epoch 44/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0077\n",
            "Epoch 45/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0042\n",
            "Epoch 46/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0042\n",
            "Epoch 47/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0043\n",
            "Epoch 48/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0041\n",
            "Epoch 49/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0039\n",
            "Epoch 50/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0041\n",
            "Epoch 51/1000\n",
            "160/160 [==============================] - 0s 100us/step - loss: 0.0047\n",
            "Epoch 52/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0050\n",
            "Epoch 53/1000\n",
            "160/160 [==============================] - 0s 95us/step - loss: 0.0090\n",
            "Epoch 54/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0103\n",
            "Epoch 55/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0038\n",
            "Epoch 56/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0037\n",
            "Epoch 57/1000\n",
            "160/160 [==============================] - 0s 96us/step - loss: 0.0063\n",
            "Epoch 58/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0046\n",
            "Epoch 59/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0157\n",
            "Epoch 60/1000\n",
            "160/160 [==============================] - 0s 96us/step - loss: 0.0816\n",
            "Epoch 61/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0317\n",
            "Epoch 62/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0136\n",
            "Epoch 63/1000\n",
            "160/160 [==============================] - 0s 98us/step - loss: 0.0056\n",
            "Epoch 64/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0040\n",
            "Epoch 65/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0045\n",
            "Epoch 66/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0046\n",
            "Epoch 67/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0047\n",
            "Epoch 68/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0039\n",
            "Epoch 69/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0061\n",
            "Epoch 70/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0045\n",
            "Epoch 71/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0044\n",
            "Epoch 72/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0046\n",
            "Epoch 73/1000\n",
            "160/160 [==============================] - 0s 106us/step - loss: 0.0058\n",
            "Epoch 74/1000\n",
            "160/160 [==============================] - 0s 129us/step - loss: 0.0046\n",
            "Epoch 75/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0054\n",
            "Epoch 76/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0040\n",
            "Epoch 77/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0041\n",
            "Epoch 78/1000\n",
            "160/160 [==============================] - 0s 108us/step - loss: 0.0039\n",
            "Epoch 79/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0078\n",
            "Epoch 80/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0039\n",
            "Epoch 81/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0041\n",
            "Epoch 82/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0041\n",
            "Epoch 83/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0041\n",
            "Epoch 84/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0069\n",
            "Epoch 85/1000\n",
            "160/160 [==============================] - 0s 98us/step - loss: 0.0043\n",
            "Epoch 86/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0045\n",
            "Epoch 87/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0041\n",
            "Epoch 88/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0038\n",
            "Epoch 89/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0040\n",
            "Epoch 90/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0150\n",
            "Epoch 91/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0051\n",
            "Epoch 92/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0044\n",
            "Epoch 93/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0099\n",
            "Epoch 94/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0257\n",
            "Epoch 95/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0055\n",
            "Epoch 96/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0036\n",
            "Epoch 97/1000\n",
            "160/160 [==============================] - 0s 109us/step - loss: 0.0037\n",
            "Epoch 98/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0045\n",
            "Epoch 99/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0036\n",
            "Epoch 100/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0037\n",
            "Epoch 101/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0036\n",
            "Epoch 102/1000\n",
            "160/160 [==============================] - 0s 103us/step - loss: 0.0048\n",
            "Epoch 103/1000\n",
            "160/160 [==============================] - 0s 116us/step - loss: 0.0038\n",
            "Epoch 104/1000\n",
            "160/160 [==============================] - 0s 115us/step - loss: 0.0042\n",
            "Epoch 105/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0040\n",
            "Epoch 106/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0036\n",
            "Epoch 107/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0042\n",
            "Epoch 108/1000\n",
            "160/160 [==============================] - 0s 106us/step - loss: 0.0047\n",
            "Epoch 109/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0049\n",
            "Epoch 110/1000\n",
            "160/160 [==============================] - 0s 103us/step - loss: 0.0049\n",
            "Epoch 111/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0056\n",
            "Epoch 112/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0072\n",
            "Epoch 113/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.1042\n",
            "Epoch 114/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.2394\n",
            "Epoch 115/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0244\n",
            "Epoch 116/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0152\n",
            "Epoch 117/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0092\n",
            "Epoch 118/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0060\n",
            "Epoch 119/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0046\n",
            "Epoch 120/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0049\n",
            "Epoch 121/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0050\n",
            "Epoch 122/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0072\n",
            "Epoch 123/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0054\n",
            "Epoch 124/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0040\n",
            "Epoch 125/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0053\n",
            "Epoch 126/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0055\n",
            "Epoch 127/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0039\n",
            "Epoch 128/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0043\n",
            "Epoch 129/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0050\n",
            "Epoch 130/1000\n",
            "160/160 [==============================] - 0s 99us/step - loss: 0.0038\n",
            "Epoch 131/1000\n",
            "160/160 [==============================] - 0s 108us/step - loss: 0.0041\n",
            "Epoch 132/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0042\n",
            "Epoch 133/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0042\n",
            "Epoch 134/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0040\n",
            "Epoch 135/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0041\n",
            "Epoch 136/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0040\n",
            "Epoch 137/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0039\n",
            "Epoch 138/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0036\n",
            "Epoch 139/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0036\n",
            "Epoch 140/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0037\n",
            "Epoch 141/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0038\n",
            "Epoch 142/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0059\n",
            "Epoch 143/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0039\n",
            "Epoch 144/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0036\n",
            "Epoch 145/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0057\n",
            "Epoch 146/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0053\n",
            "Epoch 147/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0041\n",
            "Epoch 148/1000\n",
            "160/160 [==============================] - 0s 96us/step - loss: 0.0061\n",
            "Epoch 149/1000\n",
            "160/160 [==============================] - 0s 97us/step - loss: 0.0039\n",
            "Epoch 150/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0202\n",
            "Epoch 151/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0051\n",
            "Epoch 152/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0040\n",
            "Epoch 153/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0106\n",
            "Epoch 154/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0049\n",
            "Epoch 155/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0036\n",
            "Epoch 156/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0038\n",
            "Epoch 157/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0040\n",
            "Epoch 158/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0087\n",
            "Epoch 159/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0123\n",
            "Epoch 160/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0045\n",
            "Epoch 161/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0043\n",
            "Epoch 162/1000\n",
            "160/160 [==============================] - 0s 99us/step - loss: 0.0040\n",
            "Epoch 163/1000\n",
            "160/160 [==============================] - 0s 128us/step - loss: 0.0045\n",
            "Epoch 164/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0062\n",
            "Epoch 165/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0059\n",
            "Epoch 166/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0087\n",
            "Epoch 167/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0041\n",
            "Epoch 168/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0040\n",
            "Epoch 169/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0038\n",
            "Epoch 170/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0040\n",
            "Epoch 171/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0037\n",
            "Epoch 172/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0038\n",
            "Epoch 173/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0036\n",
            "Epoch 174/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0037\n",
            "Epoch 175/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0067\n",
            "Epoch 176/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0058\n",
            "Epoch 177/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0053\n",
            "Epoch 178/1000\n",
            "160/160 [==============================] - 0s 95us/step - loss: 0.0077\n",
            "Epoch 179/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0050\n",
            "Epoch 180/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0037\n",
            "Epoch 181/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0036\n",
            "Epoch 182/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0035\n",
            "Epoch 183/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0051\n",
            "Epoch 184/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0041\n",
            "Epoch 185/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0040\n",
            "Epoch 186/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0050\n",
            "Epoch 187/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0042\n",
            "Epoch 188/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0037\n",
            "Epoch 189/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0035\n",
            "Epoch 190/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0038\n",
            "Epoch 191/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0039\n",
            "Epoch 192/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0045\n",
            "Epoch 193/1000\n",
            "160/160 [==============================] - 0s 103us/step - loss: 0.0036\n",
            "Epoch 194/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0042\n",
            "Epoch 195/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0036\n",
            "Epoch 196/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0037\n",
            "Epoch 197/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0043\n",
            "Epoch 198/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0071\n",
            "Epoch 199/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0072\n",
            "Epoch 200/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0036\n",
            "Epoch 201/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0035\n",
            "Epoch 202/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0037\n",
            "Epoch 203/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0043\n",
            "Epoch 204/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0069\n",
            "Epoch 205/1000\n",
            "160/160 [==============================] - 0s 98us/step - loss: 0.0076\n",
            "Epoch 206/1000\n",
            "160/160 [==============================] - 0s 101us/step - loss: 0.0061\n",
            "Epoch 207/1000\n",
            "160/160 [==============================] - 0s 95us/step - loss: 0.0663\n",
            "Epoch 208/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0121\n",
            "Epoch 209/1000\n",
            "160/160 [==============================] - 0s 103us/step - loss: 0.0046\n",
            "Epoch 210/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0050\n",
            "Epoch 211/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0785\n",
            "Epoch 212/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0250\n",
            "Epoch 213/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0038\n",
            "Epoch 214/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0041\n",
            "Epoch 215/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0048\n",
            "Epoch 216/1000\n",
            "160/160 [==============================] - 0s 107us/step - loss: 0.0169\n",
            "Epoch 217/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0036\n",
            "Epoch 218/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0084\n",
            "Epoch 219/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0057\n",
            "Epoch 220/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0038\n",
            "Epoch 221/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0038\n",
            "Epoch 222/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0059\n",
            "Epoch 223/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0035\n",
            "Epoch 224/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0049\n",
            "Epoch 225/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0037\n",
            "Epoch 226/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0053\n",
            "Epoch 227/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0037\n",
            "Epoch 228/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0038\n",
            "Epoch 229/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0040\n",
            "Epoch 230/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0035\n",
            "Epoch 231/1000\n",
            "160/160 [==============================] - 0s 100us/step - loss: 0.0048\n",
            "Epoch 232/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0041\n",
            "Epoch 233/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0041\n",
            "Epoch 234/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0108\n",
            "Epoch 235/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0045\n",
            "Epoch 236/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0038\n",
            "Epoch 237/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0040\n",
            "Epoch 238/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0069\n",
            "Epoch 239/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0041\n",
            "Epoch 240/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0037\n",
            "Epoch 241/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0042\n",
            "Epoch 242/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0062\n",
            "Epoch 243/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0058\n",
            "Epoch 244/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0054\n",
            "Epoch 245/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0067\n",
            "Epoch 246/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0039\n",
            "Epoch 247/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0048\n",
            "Epoch 248/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0034\n",
            "Epoch 249/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0036\n",
            "Epoch 250/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0043\n",
            "Epoch 251/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0034\n",
            "Epoch 252/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0039\n",
            "Epoch 253/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0037\n",
            "Epoch 254/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0044\n",
            "Epoch 255/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0037\n",
            "Epoch 256/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0040\n",
            "Epoch 257/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0040\n",
            "Epoch 258/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0043\n",
            "Epoch 259/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0080\n",
            "Epoch 260/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0146\n",
            "Epoch 261/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0042\n",
            "Epoch 262/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0036\n",
            "Epoch 263/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0061\n",
            "Epoch 264/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0076\n",
            "Epoch 265/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0037\n",
            "Epoch 266/1000\n",
            "160/160 [==============================] - 0s 107us/step - loss: 0.0035\n",
            "Epoch 267/1000\n",
            "160/160 [==============================] - 0s 103us/step - loss: 0.0036\n",
            "Epoch 268/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0044\n",
            "Epoch 269/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0050\n",
            "Epoch 270/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0039\n",
            "Epoch 271/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0043\n",
            "Epoch 272/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0068\n",
            "Epoch 273/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0049\n",
            "Epoch 274/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0038\n",
            "Epoch 275/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0035\n",
            "Epoch 276/1000\n",
            "160/160 [==============================] - 0s 118us/step - loss: 0.0038\n",
            "Epoch 277/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0050\n",
            "Epoch 278/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0161\n",
            "Epoch 279/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0052\n",
            "Epoch 280/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0041\n",
            "Epoch 281/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0048\n",
            "Epoch 282/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0049\n",
            "Epoch 283/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0041\n",
            "Epoch 284/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0037\n",
            "Epoch 285/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0042\n",
            "Epoch 286/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0040\n",
            "Epoch 287/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0037\n",
            "Epoch 288/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0042\n",
            "Epoch 289/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0056\n",
            "Epoch 290/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0082\n",
            "Epoch 291/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0048\n",
            "Epoch 292/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0036\n",
            "Epoch 293/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0035\n",
            "Epoch 294/1000\n",
            "160/160 [==============================] - 0s 102us/step - loss: 0.0049\n",
            "Epoch 295/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0038\n",
            "Epoch 296/1000\n",
            "160/160 [==============================] - 0s 105us/step - loss: 0.0036\n",
            "Epoch 297/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0034\n",
            "Epoch 298/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0060\n",
            "Epoch 299/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0208\n",
            "Epoch 300/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0081\n",
            "Epoch 301/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0117\n",
            "Epoch 302/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0150\n",
            "Epoch 303/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0039\n",
            "Epoch 304/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0036\n",
            "Epoch 305/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0035\n",
            "Epoch 306/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0050\n",
            "Epoch 307/1000\n",
            "160/160 [==============================] - 0s 96us/step - loss: 0.0042\n",
            "Epoch 308/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0050\n",
            "Epoch 309/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0034\n",
            "Epoch 310/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0037\n",
            "Epoch 311/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0040\n",
            "Epoch 312/1000\n",
            "160/160 [==============================] - 0s 96us/step - loss: 0.0048\n",
            "Epoch 313/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0036\n",
            "Epoch 314/1000\n",
            "160/160 [==============================] - 0s 99us/step - loss: 0.0034\n",
            "Epoch 315/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0047\n",
            "Epoch 316/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0266\n",
            "Epoch 317/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0082\n",
            "Epoch 318/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0246\n",
            "Epoch 319/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0208\n",
            "Epoch 320/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0052\n",
            "Epoch 321/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0041\n",
            "Epoch 322/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0036\n",
            "Epoch 323/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0040\n",
            "Epoch 324/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0154\n",
            "Epoch 325/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0067\n",
            "Epoch 326/1000\n",
            "160/160 [==============================] - 0s 114us/step - loss: 0.0040\n",
            "Epoch 327/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0060\n",
            "Epoch 328/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0045\n",
            "Epoch 329/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0040\n",
            "Epoch 330/1000\n",
            "160/160 [==============================] - 0s 109us/step - loss: 0.0034\n",
            "Epoch 331/1000\n",
            "160/160 [==============================] - 0s 100us/step - loss: 0.0043\n",
            "Epoch 332/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0045\n",
            "Epoch 333/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0086\n",
            "Epoch 334/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0036\n",
            "Epoch 335/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0046\n",
            "Epoch 336/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0134\n",
            "Epoch 337/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0146\n",
            "Epoch 338/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0855\n",
            "Epoch 339/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.5224\n",
            "Epoch 340/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0386\n",
            "Epoch 341/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0098\n",
            "Epoch 342/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0090\n",
            "Epoch 343/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0040\n",
            "Epoch 344/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0043\n",
            "Epoch 345/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0046\n",
            "Epoch 346/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0057\n",
            "Epoch 347/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0038\n",
            "Epoch 348/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0061\n",
            "Epoch 349/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0034\n",
            "Epoch 350/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0038\n",
            "Epoch 351/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0035\n",
            "Epoch 352/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0054\n",
            "Epoch 353/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0067\n",
            "Epoch 354/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0037\n",
            "Epoch 355/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0035\n",
            "Epoch 356/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0036\n",
            "Epoch 357/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0035\n",
            "Epoch 358/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0046\n",
            "Epoch 359/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0034\n",
            "Epoch 360/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0038\n",
            "Epoch 361/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0069\n",
            "Epoch 362/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0059\n",
            "Epoch 363/1000\n",
            "160/160 [==============================] - 0s 95us/step - loss: 0.0050\n",
            "Epoch 364/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0045\n",
            "Epoch 365/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0066\n",
            "Epoch 366/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0036\n",
            "Epoch 367/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0093\n",
            "Epoch 368/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0065\n",
            "Epoch 369/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0040\n",
            "Epoch 370/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0036\n",
            "Epoch 371/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0034\n",
            "Epoch 372/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0034\n",
            "Epoch 373/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0034\n",
            "Epoch 374/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0036\n",
            "Epoch 375/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0047\n",
            "Epoch 376/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0035\n",
            "Epoch 377/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0038\n",
            "Epoch 378/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0061\n",
            "Epoch 379/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0036\n",
            "Epoch 380/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0036\n",
            "Epoch 381/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0037\n",
            "Epoch 382/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0079\n",
            "Epoch 383/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0043\n",
            "Epoch 384/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0050\n",
            "Epoch 385/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0042\n",
            "Epoch 386/1000\n",
            "160/160 [==============================] - 0s 101us/step - loss: 0.0049\n",
            "Epoch 387/1000\n",
            "160/160 [==============================] - 0s 111us/step - loss: 0.0037\n",
            "Epoch 388/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0042\n",
            "Epoch 389/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0062\n",
            "Epoch 390/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0099\n",
            "Epoch 391/1000\n",
            "160/160 [==============================] - 0s 101us/step - loss: 0.0060\n",
            "Epoch 392/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0045\n",
            "Epoch 393/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0091\n",
            "Epoch 394/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0051\n",
            "Epoch 395/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0048\n",
            "Epoch 396/1000\n",
            "160/160 [==============================] - 0s 107us/step - loss: 0.0041\n",
            "Epoch 397/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0037\n",
            "Epoch 398/1000\n",
            "160/160 [==============================] - 0s 99us/step - loss: 0.0047\n",
            "Epoch 399/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0042\n",
            "Epoch 400/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0039\n",
            "Epoch 401/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0050\n",
            "Epoch 402/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0036\n",
            "Epoch 403/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0037\n",
            "Epoch 404/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0036\n",
            "Epoch 405/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0051\n",
            "Epoch 406/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0076\n",
            "Epoch 407/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0114\n",
            "Epoch 408/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0082\n",
            "Epoch 409/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0053\n",
            "Epoch 410/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0034\n",
            "Epoch 411/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0038\n",
            "Epoch 412/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0043\n",
            "Epoch 413/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0038\n",
            "Epoch 414/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0034\n",
            "Epoch 415/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0034\n",
            "Epoch 416/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0035\n",
            "Epoch 417/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0037\n",
            "Epoch 418/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0069\n",
            "Epoch 419/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0125\n",
            "Epoch 420/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0317\n",
            "Epoch 421/1000\n",
            "160/160 [==============================] - 0s 97us/step - loss: 0.0145\n",
            "Epoch 422/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0061\n",
            "Epoch 423/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0034\n",
            "Epoch 424/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0053\n",
            "Epoch 425/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0045\n",
            "Epoch 426/1000\n",
            "160/160 [==============================] - 0s 98us/step - loss: 0.0037\n",
            "Epoch 427/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0067\n",
            "Epoch 428/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0037\n",
            "Epoch 429/1000\n",
            "160/160 [==============================] - 0s 105us/step - loss: 0.0040\n",
            "Epoch 430/1000\n",
            "160/160 [==============================] - 0s 105us/step - loss: 0.0049\n",
            "Epoch 431/1000\n",
            "160/160 [==============================] - 0s 137us/step - loss: 0.0094\n",
            "Epoch 432/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0036\n",
            "Epoch 433/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0039\n",
            "Epoch 434/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0058\n",
            "Epoch 435/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0058\n",
            "Epoch 436/1000\n",
            "160/160 [==============================] - 0s 125us/step - loss: 0.0034\n",
            "Epoch 437/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0054\n",
            "Epoch 438/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0427\n",
            "Epoch 439/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0746\n",
            "Epoch 440/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.1375\n",
            "Epoch 441/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0118\n",
            "Epoch 442/1000\n",
            "160/160 [==============================] - 0s 99us/step - loss: 0.0048\n",
            "Epoch 443/1000\n",
            "160/160 [==============================] - 0s 98us/step - loss: 0.0039\n",
            "Epoch 444/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0042\n",
            "Epoch 445/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0041\n",
            "Epoch 446/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0033\n",
            "Epoch 447/1000\n",
            "160/160 [==============================] - 0s 103us/step - loss: 0.0047\n",
            "Epoch 448/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0062\n",
            "Epoch 449/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0054\n",
            "Epoch 450/1000\n",
            "160/160 [==============================] - 0s 107us/step - loss: 0.0037\n",
            "Epoch 451/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0051\n",
            "Epoch 452/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0110\n",
            "Epoch 453/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0440\n",
            "Epoch 454/1000\n",
            "160/160 [==============================] - 0s 105us/step - loss: 0.0036\n",
            "Epoch 455/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0037\n",
            "Epoch 456/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0069\n",
            "Epoch 457/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0075\n",
            "Epoch 458/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0051\n",
            "Epoch 459/1000\n",
            "160/160 [==============================] - 0s 95us/step - loss: 0.0058\n",
            "Epoch 460/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0041\n",
            "Epoch 461/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0033\n",
            "Epoch 462/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0035\n",
            "Epoch 463/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0035\n",
            "Epoch 464/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0042\n",
            "Epoch 465/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0042\n",
            "Epoch 466/1000\n",
            "160/160 [==============================] - 0s 98us/step - loss: 0.0036\n",
            "Epoch 467/1000\n",
            "160/160 [==============================] - 0s 102us/step - loss: 0.0041\n",
            "Epoch 468/1000\n",
            "160/160 [==============================] - 0s 134us/step - loss: 0.0038\n",
            "Epoch 469/1000\n",
            "160/160 [==============================] - 0s 105us/step - loss: 0.0037\n",
            "Epoch 470/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0034\n",
            "Epoch 471/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0034\n",
            "Epoch 472/1000\n",
            "160/160 [==============================] - 0s 102us/step - loss: 0.0039\n",
            "Epoch 473/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0036\n",
            "Epoch 474/1000\n",
            "160/160 [==============================] - 0s 97us/step - loss: 0.0037\n",
            "Epoch 475/1000\n",
            "160/160 [==============================] - 0s 97us/step - loss: 0.0139\n",
            "Epoch 476/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0101\n",
            "Epoch 477/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0067\n",
            "Epoch 478/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0106\n",
            "Epoch 479/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0072\n",
            "Epoch 480/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0167\n",
            "Epoch 481/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0069\n",
            "Epoch 482/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0040\n",
            "Epoch 483/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0037\n",
            "Epoch 484/1000\n",
            "160/160 [==============================] - 0s 96us/step - loss: 0.0046\n",
            "Epoch 485/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0064\n",
            "Epoch 486/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0093\n",
            "Epoch 487/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0091\n",
            "Epoch 488/1000\n",
            "160/160 [==============================] - 0s 104us/step - loss: 0.0124\n",
            "Epoch 489/1000\n",
            "160/160 [==============================] - 0s 109us/step - loss: 0.0308\n",
            "Epoch 490/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0060\n",
            "Epoch 491/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0043\n",
            "Epoch 492/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0033\n",
            "Epoch 493/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0035\n",
            "Epoch 494/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0034\n",
            "Epoch 495/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0037\n",
            "Epoch 496/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0042\n",
            "Epoch 497/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0035\n",
            "Epoch 498/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0033\n",
            "Epoch 499/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0044\n",
            "Epoch 500/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0063\n",
            "Epoch 501/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0047\n",
            "Epoch 502/1000\n",
            "160/160 [==============================] - 0s 98us/step - loss: 0.0067\n",
            "Epoch 503/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0052\n",
            "Epoch 504/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0036\n",
            "Epoch 505/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0041\n",
            "Epoch 506/1000\n",
            "160/160 [==============================] - 0s 105us/step - loss: 0.0035\n",
            "Epoch 507/1000\n",
            "160/160 [==============================] - 0s 119us/step - loss: 0.0091\n",
            "Epoch 508/1000\n",
            "160/160 [==============================] - 0s 133us/step - loss: 0.0045\n",
            "Epoch 509/1000\n",
            "160/160 [==============================] - 0s 98us/step - loss: 0.0039\n",
            "Epoch 510/1000\n",
            "160/160 [==============================] - 0s 127us/step - loss: 0.0055\n",
            "Epoch 511/1000\n",
            "160/160 [==============================] - 0s 107us/step - loss: 0.0108\n",
            "Epoch 512/1000\n",
            "160/160 [==============================] - 0s 100us/step - loss: 0.0155\n",
            "Epoch 513/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0283\n",
            "Epoch 514/1000\n",
            "160/160 [==============================] - 0s 97us/step - loss: 0.0308\n",
            "Epoch 515/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0594\n",
            "Epoch 516/1000\n",
            "160/160 [==============================] - 0s 125us/step - loss: 0.1628\n",
            "Epoch 517/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0092\n",
            "Epoch 518/1000\n",
            "160/160 [==============================] - 0s 113us/step - loss: 0.0032\n",
            "Epoch 519/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0059\n",
            "Epoch 520/1000\n",
            "160/160 [==============================] - 0s 109us/step - loss: 0.0119\n",
            "Epoch 521/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0042\n",
            "Epoch 522/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0034\n",
            "Epoch 523/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0033\n",
            "Epoch 524/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0033\n",
            "Epoch 525/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0035\n",
            "Epoch 526/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0035\n",
            "Epoch 527/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0036\n",
            "Epoch 528/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0038\n",
            "Epoch 529/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0034\n",
            "Epoch 530/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0034\n",
            "Epoch 531/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0047\n",
            "Epoch 532/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0093\n",
            "Epoch 533/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0418\n",
            "Epoch 534/1000\n",
            "160/160 [==============================] - 0s 95us/step - loss: 0.0065\n",
            "Epoch 535/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0101\n",
            "Epoch 536/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0035\n",
            "Epoch 537/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0055\n",
            "Epoch 538/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0049\n",
            "Epoch 539/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0084\n",
            "Epoch 540/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0044\n",
            "Epoch 541/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0037\n",
            "Epoch 542/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0047\n",
            "Epoch 543/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0051\n",
            "Epoch 544/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0035\n",
            "Epoch 545/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0094\n",
            "Epoch 546/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0117\n",
            "Epoch 547/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0270\n",
            "Epoch 548/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0171\n",
            "Epoch 549/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0105\n",
            "Epoch 550/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0053\n",
            "Epoch 551/1000\n",
            "160/160 [==============================] - 0s 109us/step - loss: 0.0065\n",
            "Epoch 552/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0064\n",
            "Epoch 553/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0040\n",
            "Epoch 554/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0049\n",
            "Epoch 555/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0034\n",
            "Epoch 556/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0035\n",
            "Epoch 557/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0035\n",
            "Epoch 558/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0034\n",
            "Epoch 559/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0057\n",
            "Epoch 560/1000\n",
            "160/160 [==============================] - 0s 96us/step - loss: 0.0037\n",
            "Epoch 561/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0042\n",
            "Epoch 562/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0037\n",
            "Epoch 563/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0034\n",
            "Epoch 564/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0033\n",
            "Epoch 565/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0042\n",
            "Epoch 566/1000\n",
            "160/160 [==============================] - 0s 110us/step - loss: 0.0034\n",
            "Epoch 567/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0089\n",
            "Epoch 568/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0063\n",
            "Epoch 569/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0044\n",
            "Epoch 570/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0036\n",
            "Epoch 571/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0039\n",
            "Epoch 572/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0036\n",
            "Epoch 573/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0034\n",
            "Epoch 574/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0050\n",
            "Epoch 575/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0034\n",
            "Epoch 576/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0035\n",
            "Epoch 577/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0032\n",
            "Epoch 578/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0046\n",
            "Epoch 579/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0034\n",
            "Epoch 580/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0064\n",
            "Epoch 581/1000\n",
            "160/160 [==============================] - 0s 100us/step - loss: 0.0035\n",
            "Epoch 582/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0035\n",
            "Epoch 583/1000\n",
            "160/160 [==============================] - 0s 101us/step - loss: 0.0034\n",
            "Epoch 584/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0038\n",
            "Epoch 585/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0045\n",
            "Epoch 586/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0037\n",
            "Epoch 587/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0058\n",
            "Epoch 588/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0057\n",
            "Epoch 589/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0034\n",
            "Epoch 590/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0040\n",
            "Epoch 591/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0197\n",
            "Epoch 592/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0040\n",
            "Epoch 593/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0038\n",
            "Epoch 594/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0062\n",
            "Epoch 595/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0035\n",
            "Epoch 596/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0276\n",
            "Epoch 597/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0140\n",
            "Epoch 598/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0037\n",
            "Epoch 599/1000\n",
            "160/160 [==============================] - 0s 91us/step - loss: 0.0044\n",
            "Epoch 600/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0055\n",
            "Epoch 601/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0032\n",
            "Epoch 602/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0055\n",
            "Epoch 603/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0047\n",
            "Epoch 604/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0061\n",
            "Epoch 605/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0033\n",
            "Epoch 606/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0040\n",
            "Epoch 607/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0065\n",
            "Epoch 608/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0043\n",
            "Epoch 609/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0039\n",
            "Epoch 610/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0120\n",
            "Epoch 611/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0130\n",
            "Epoch 612/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0089\n",
            "Epoch 613/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0099\n",
            "Epoch 614/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0133\n",
            "Epoch 615/1000\n",
            "160/160 [==============================] - 0s 112us/step - loss: 0.0739\n",
            "Epoch 616/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0245\n",
            "Epoch 617/1000\n",
            "160/160 [==============================] - 0s 109us/step - loss: 0.1000\n",
            "Epoch 618/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0051\n",
            "Epoch 619/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0054\n",
            "Epoch 620/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0110\n",
            "Epoch 621/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0064\n",
            "Epoch 622/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0119\n",
            "Epoch 623/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0408\n",
            "Epoch 624/1000\n",
            "160/160 [==============================] - 0s 106us/step - loss: 0.0285\n",
            "Epoch 625/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0073\n",
            "Epoch 626/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0037\n",
            "Epoch 627/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0032\n",
            "Epoch 628/1000\n",
            "160/160 [==============================] - 0s 95us/step - loss: 0.0035\n",
            "Epoch 629/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0040\n",
            "Epoch 630/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0044\n",
            "Epoch 631/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0033\n",
            "Epoch 632/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0051\n",
            "Epoch 633/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0052\n",
            "Epoch 634/1000\n",
            "160/160 [==============================] - 0s 103us/step - loss: 0.0419\n",
            "Epoch 635/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0054\n",
            "Epoch 636/1000\n",
            "160/160 [==============================] - 0s 99us/step - loss: 0.0078\n",
            "Epoch 637/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0036\n",
            "Epoch 638/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0033\n",
            "Epoch 639/1000\n",
            "160/160 [==============================] - 0s 98us/step - loss: 0.0061\n",
            "Epoch 640/1000\n",
            "160/160 [==============================] - 0s 105us/step - loss: 0.0044\n",
            "Epoch 641/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0081\n",
            "Epoch 642/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0137\n",
            "Epoch 643/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0035\n",
            "Epoch 644/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0051\n",
            "Epoch 645/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0060\n",
            "Epoch 646/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0033\n",
            "Epoch 647/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0033\n",
            "Epoch 648/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0047\n",
            "Epoch 649/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0037\n",
            "Epoch 650/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0035\n",
            "Epoch 651/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0041\n",
            "Epoch 652/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0037\n",
            "Epoch 653/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0098\n",
            "Epoch 654/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0039\n",
            "Epoch 655/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0042\n",
            "Epoch 656/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0172\n",
            "Epoch 657/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0262\n",
            "Epoch 658/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0064\n",
            "Epoch 659/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0074\n",
            "Epoch 660/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0049\n",
            "Epoch 661/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0042\n",
            "Epoch 662/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0217\n",
            "Epoch 663/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0080\n",
            "Epoch 664/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0051\n",
            "Epoch 665/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0335\n",
            "Epoch 666/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0060\n",
            "Epoch 667/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0037\n",
            "Epoch 668/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0046\n",
            "Epoch 669/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0036\n",
            "Epoch 670/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0033\n",
            "Epoch 671/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0034\n",
            "Epoch 672/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0033\n",
            "Epoch 673/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0034\n",
            "Epoch 674/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0037\n",
            "Epoch 675/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0033\n",
            "Epoch 676/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0036\n",
            "Epoch 677/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0032\n",
            "Epoch 678/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0035\n",
            "Epoch 679/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0055\n",
            "Epoch 680/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0038\n",
            "Epoch 681/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0034\n",
            "Epoch 682/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0118\n",
            "Epoch 683/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0575\n",
            "Epoch 684/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0038\n",
            "Epoch 685/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0033\n",
            "Epoch 686/1000\n",
            "160/160 [==============================] - 0s 104us/step - loss: 0.0041\n",
            "Epoch 687/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0067\n",
            "Epoch 688/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0088\n",
            "Epoch 689/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.1426\n",
            "Epoch 690/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0874\n",
            "Epoch 691/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0228\n",
            "Epoch 692/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0040\n",
            "Epoch 693/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0053\n",
            "Epoch 694/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0040\n",
            "Epoch 695/1000\n",
            "160/160 [==============================] - 0s 105us/step - loss: 0.0043\n",
            "Epoch 696/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0035\n",
            "Epoch 697/1000\n",
            "160/160 [==============================] - 0s 103us/step - loss: 0.0062\n",
            "Epoch 698/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0050\n",
            "Epoch 699/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0049\n",
            "Epoch 700/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0213\n",
            "Epoch 701/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0163\n",
            "Epoch 702/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0033\n",
            "Epoch 703/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0035\n",
            "Epoch 704/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0041\n",
            "Epoch 705/1000\n",
            "160/160 [==============================] - 0s 96us/step - loss: 0.0061\n",
            "Epoch 706/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0049\n",
            "Epoch 707/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0149\n",
            "Epoch 708/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0098\n",
            "Epoch 709/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0140\n",
            "Epoch 710/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0119\n",
            "Epoch 711/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0114\n",
            "Epoch 712/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0673\n",
            "Epoch 713/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0060\n",
            "Epoch 714/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0070\n",
            "Epoch 715/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0033\n",
            "Epoch 716/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0050\n",
            "Epoch 717/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0041\n",
            "Epoch 718/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0037\n",
            "Epoch 719/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0042\n",
            "Epoch 720/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0070\n",
            "Epoch 721/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0043\n",
            "Epoch 722/1000\n",
            "160/160 [==============================] - 0s 97us/step - loss: 0.0042\n",
            "Epoch 723/1000\n",
            "160/160 [==============================] - 0s 100us/step - loss: 0.0183\n",
            "Epoch 724/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0893\n",
            "Epoch 725/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0295\n",
            "Epoch 726/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0067\n",
            "Epoch 727/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0048\n",
            "Epoch 728/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0079\n",
            "Epoch 729/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0060\n",
            "Epoch 730/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0035\n",
            "Epoch 731/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0032\n",
            "Epoch 732/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0042\n",
            "Epoch 733/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0043\n",
            "Epoch 734/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0040\n",
            "Epoch 735/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0038\n",
            "Epoch 736/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0048\n",
            "Epoch 737/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0203\n",
            "Epoch 738/1000\n",
            "160/160 [==============================] - 0s 60us/step - loss: 0.0071\n",
            "Epoch 739/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0033\n",
            "Epoch 740/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0034\n",
            "Epoch 741/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0033\n",
            "Epoch 742/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0037\n",
            "Epoch 743/1000\n",
            "160/160 [==============================] - 0s 108us/step - loss: 0.0033\n",
            "Epoch 744/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0048\n",
            "Epoch 745/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0054\n",
            "Epoch 746/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0114\n",
            "Epoch 747/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.1874\n",
            "Epoch 748/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0472\n",
            "Epoch 749/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0136\n",
            "Epoch 750/1000\n",
            "160/160 [==============================] - 0s 60us/step - loss: 0.0155\n",
            "Epoch 751/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0114\n",
            "Epoch 752/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0079\n",
            "Epoch 753/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0033\n",
            "Epoch 754/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0034\n",
            "Epoch 755/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0039\n",
            "Epoch 756/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0033\n",
            "Epoch 757/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0035\n",
            "Epoch 758/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0055\n",
            "Epoch 759/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0048\n",
            "Epoch 760/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0058\n",
            "Epoch 761/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0031\n",
            "Epoch 762/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0035\n",
            "Epoch 763/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0033\n",
            "Epoch 764/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0045\n",
            "Epoch 765/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0047\n",
            "Epoch 766/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0034\n",
            "Epoch 767/1000\n",
            "160/160 [==============================] - 0s 104us/step - loss: 0.0051\n",
            "Epoch 768/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0118\n",
            "Epoch 769/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0234\n",
            "Epoch 770/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0119\n",
            "Epoch 771/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0037\n",
            "Epoch 772/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0042\n",
            "Epoch 773/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0038\n",
            "Epoch 774/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0051\n",
            "Epoch 775/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0039\n",
            "Epoch 776/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0075\n",
            "Epoch 777/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0035\n",
            "Epoch 778/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0034\n",
            "Epoch 779/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0033\n",
            "Epoch 780/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0043\n",
            "Epoch 781/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0039\n",
            "Epoch 782/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0051\n",
            "Epoch 783/1000\n",
            "160/160 [==============================] - 0s 83us/step - loss: 0.0139\n",
            "Epoch 784/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0049\n",
            "Epoch 785/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0041\n",
            "Epoch 786/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0045\n",
            "Epoch 787/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0034\n",
            "Epoch 788/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0033\n",
            "Epoch 789/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0044\n",
            "Epoch 790/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0046\n",
            "Epoch 791/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0087\n",
            "Epoch 792/1000\n",
            "160/160 [==============================] - 0s 94us/step - loss: 0.0037\n",
            "Epoch 793/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0033\n",
            "Epoch 794/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0032\n",
            "Epoch 795/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0034\n",
            "Epoch 796/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0036\n",
            "Epoch 797/1000\n",
            "160/160 [==============================] - 0s 59us/step - loss: 0.0041\n",
            "Epoch 798/1000\n",
            "160/160 [==============================] - 0s 102us/step - loss: 0.0034\n",
            "Epoch 799/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0044\n",
            "Epoch 800/1000\n",
            "160/160 [==============================] - 0s 60us/step - loss: 0.0034\n",
            "Epoch 801/1000\n",
            "160/160 [==============================] - 0s 101us/step - loss: 0.0039\n",
            "Epoch 802/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0035\n",
            "Epoch 803/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0076\n",
            "Epoch 804/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0051\n",
            "Epoch 805/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0056\n",
            "Epoch 806/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0060\n",
            "Epoch 807/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0098\n",
            "Epoch 808/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0040\n",
            "Epoch 809/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0032\n",
            "Epoch 810/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0041\n",
            "Epoch 811/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0095\n",
            "Epoch 812/1000\n",
            "160/160 [==============================] - 0s 60us/step - loss: 0.0046\n",
            "Epoch 813/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0035\n",
            "Epoch 814/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0094\n",
            "Epoch 815/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0031\n",
            "Epoch 816/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0031\n",
            "Epoch 817/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0033\n",
            "Epoch 818/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0041\n",
            "Epoch 819/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0071\n",
            "Epoch 820/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0051\n",
            "Epoch 821/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0041\n",
            "Epoch 822/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0034\n",
            "Epoch 823/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0068\n",
            "Epoch 824/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0224\n",
            "Epoch 825/1000\n",
            "160/160 [==============================] - 0s 95us/step - loss: 0.0242\n",
            "Epoch 826/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.1153\n",
            "Epoch 827/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0565\n",
            "Epoch 828/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0059\n",
            "Epoch 829/1000\n",
            "160/160 [==============================] - 0s 60us/step - loss: 0.0033\n",
            "Epoch 830/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0033\n",
            "Epoch 831/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0072\n",
            "Epoch 832/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0050\n",
            "Epoch 833/1000\n",
            "160/160 [==============================] - 0s 105us/step - loss: 0.0065\n",
            "Epoch 834/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0142\n",
            "Epoch 835/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0059\n",
            "Epoch 836/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0349\n",
            "Epoch 837/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0049\n",
            "Epoch 838/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0031\n",
            "Epoch 839/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0037\n",
            "Epoch 840/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0035\n",
            "Epoch 841/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0032\n",
            "Epoch 842/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0045\n",
            "Epoch 843/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0033\n",
            "Epoch 844/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0045\n",
            "Epoch 845/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0042\n",
            "Epoch 846/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0064\n",
            "Epoch 847/1000\n",
            "160/160 [==============================] - 0s 113us/step - loss: 0.0036\n",
            "Epoch 848/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0031\n",
            "Epoch 849/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0035\n",
            "Epoch 850/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0049\n",
            "Epoch 851/1000\n",
            "160/160 [==============================] - 0s 58us/step - loss: 0.0040\n",
            "Epoch 852/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0056\n",
            "Epoch 853/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0035\n",
            "Epoch 854/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0043\n",
            "Epoch 855/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0032\n",
            "Epoch 856/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0051\n",
            "Epoch 857/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0251\n",
            "Epoch 858/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0035\n",
            "Epoch 859/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0044\n",
            "Epoch 860/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0172\n",
            "Epoch 861/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0039\n",
            "Epoch 862/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0037\n",
            "Epoch 863/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0035\n",
            "Epoch 864/1000\n",
            "160/160 [==============================] - 0s 74us/step - loss: 0.0078\n",
            "Epoch 865/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0069\n",
            "Epoch 866/1000\n",
            "160/160 [==============================] - 0s 68us/step - loss: 0.0136\n",
            "Epoch 867/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0085\n",
            "Epoch 868/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0043\n",
            "Epoch 869/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0061\n",
            "Epoch 870/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0059\n",
            "Epoch 871/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0031\n",
            "Epoch 872/1000\n",
            "160/160 [==============================] - 0s 99us/step - loss: 0.0034\n",
            "Epoch 873/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0039\n",
            "Epoch 874/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0035\n",
            "Epoch 875/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0031\n",
            "Epoch 876/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0034\n",
            "Epoch 877/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0033\n",
            "Epoch 878/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0049\n",
            "Epoch 879/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0045\n",
            "Epoch 880/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0032\n",
            "Epoch 881/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0031\n",
            "Epoch 882/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0033\n",
            "Epoch 883/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0033\n",
            "Epoch 884/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0034\n",
            "Epoch 885/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0034\n",
            "Epoch 886/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0031\n",
            "Epoch 887/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0034\n",
            "Epoch 888/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0047\n",
            "Epoch 889/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0034\n",
            "Epoch 890/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0032\n",
            "Epoch 891/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0079\n",
            "Epoch 892/1000\n",
            "160/160 [==============================] - 0s 60us/step - loss: 0.0038\n",
            "Epoch 893/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0034\n",
            "Epoch 894/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0041\n",
            "Epoch 895/1000\n",
            "160/160 [==============================] - 0s 57us/step - loss: 0.0033\n",
            "Epoch 896/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0038\n",
            "Epoch 897/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0043\n",
            "Epoch 898/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0037\n",
            "Epoch 899/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0036\n",
            "Epoch 900/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0079\n",
            "Epoch 901/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0070\n",
            "Epoch 902/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0060\n",
            "Epoch 903/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0081\n",
            "Epoch 904/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0033\n",
            "Epoch 905/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0034\n",
            "Epoch 906/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0036\n",
            "Epoch 907/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0137\n",
            "Epoch 908/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0712\n",
            "Epoch 909/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0102\n",
            "Epoch 910/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0159\n",
            "Epoch 911/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0158\n",
            "Epoch 912/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0149\n",
            "Epoch 913/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0033\n",
            "Epoch 914/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0041\n",
            "Epoch 915/1000\n",
            "160/160 [==============================] - 0s 119us/step - loss: 0.0047\n",
            "Epoch 916/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0075\n",
            "Epoch 917/1000\n",
            "160/160 [==============================] - 0s 89us/step - loss: 0.0054\n",
            "Epoch 918/1000\n",
            "160/160 [==============================] - 0s 65us/step - loss: 0.0053\n",
            "Epoch 919/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0039\n",
            "Epoch 920/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0032\n",
            "Epoch 921/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0033\n",
            "Epoch 922/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0035\n",
            "Epoch 923/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0051\n",
            "Epoch 924/1000\n",
            "160/160 [==============================] - 0s 69us/step - loss: 0.0039\n",
            "Epoch 925/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0136\n",
            "Epoch 926/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0281\n",
            "Epoch 927/1000\n",
            "160/160 [==============================] - 0s 67us/step - loss: 0.0077\n",
            "Epoch 928/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0116\n",
            "Epoch 929/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0134\n",
            "Epoch 930/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0284\n",
            "Epoch 931/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0135\n",
            "Epoch 932/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0297\n",
            "Epoch 933/1000\n",
            "160/160 [==============================] - 0s 56us/step - loss: 0.0313\n",
            "Epoch 934/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0039\n",
            "Epoch 935/1000\n",
            "160/160 [==============================] - 0s 90us/step - loss: 0.0049\n",
            "Epoch 936/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0112\n",
            "Epoch 937/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0138\n",
            "Epoch 938/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0114\n",
            "Epoch 939/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.3363\n",
            "Epoch 940/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0109\n",
            "Epoch 941/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0140\n",
            "Epoch 942/1000\n",
            "160/160 [==============================] - 0s 76us/step - loss: 0.0053\n",
            "Epoch 943/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0032\n",
            "Epoch 944/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0034\n",
            "Epoch 945/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0034\n",
            "Epoch 946/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0042\n",
            "Epoch 947/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0036\n",
            "Epoch 948/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0038\n",
            "Epoch 949/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0033\n",
            "Epoch 950/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0035\n",
            "Epoch 951/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0030\n",
            "Epoch 952/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0035\n",
            "Epoch 953/1000\n",
            "160/160 [==============================] - 0s 93us/step - loss: 0.0033\n",
            "Epoch 954/1000\n",
            "160/160 [==============================] - 0s 81us/step - loss: 0.0031\n",
            "Epoch 955/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0032\n",
            "Epoch 956/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0036\n",
            "Epoch 957/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0035\n",
            "Epoch 958/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0031\n",
            "Epoch 959/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0034\n",
            "Epoch 960/1000\n",
            "160/160 [==============================] - 0s 61us/step - loss: 0.0032\n",
            "Epoch 961/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0035\n",
            "Epoch 962/1000\n",
            "160/160 [==============================] - 0s 70us/step - loss: 0.0035\n",
            "Epoch 963/1000\n",
            "160/160 [==============================] - 0s 88us/step - loss: 0.0077\n",
            "Epoch 964/1000\n",
            "160/160 [==============================] - 0s 100us/step - loss: 0.0036\n",
            "Epoch 965/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0041\n",
            "Epoch 966/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0091\n",
            "Epoch 967/1000\n",
            "160/160 [==============================] - 0s 92us/step - loss: 0.0040\n",
            "Epoch 968/1000\n",
            "160/160 [==============================] - 0s 84us/step - loss: 0.0063\n",
            "Epoch 969/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0071\n",
            "Epoch 970/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0106\n",
            "Epoch 971/1000\n",
            "160/160 [==============================] - 0s 75us/step - loss: 0.0138\n",
            "Epoch 972/1000\n",
            "160/160 [==============================] - 0s 56us/step - loss: 0.0059\n",
            "Epoch 973/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.1426\n",
            "Epoch 974/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0110\n",
            "Epoch 975/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0123\n",
            "Epoch 976/1000\n",
            "160/160 [==============================] - 0s 96us/step - loss: 0.0061\n",
            "Epoch 977/1000\n",
            "160/160 [==============================] - 0s 82us/step - loss: 0.0034\n",
            "Epoch 978/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0034\n",
            "Epoch 979/1000\n",
            "160/160 [==============================] - 0s 72us/step - loss: 0.0049\n",
            "Epoch 980/1000\n",
            "160/160 [==============================] - 0s 73us/step - loss: 0.0035\n",
            "Epoch 981/1000\n",
            "160/160 [==============================] - 0s 77us/step - loss: 0.0034\n",
            "Epoch 982/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0070\n",
            "Epoch 983/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0031\n",
            "Epoch 984/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0031\n",
            "Epoch 985/1000\n",
            "160/160 [==============================] - 0s 87us/step - loss: 0.0041\n",
            "Epoch 986/1000\n",
            "160/160 [==============================] - 0s 86us/step - loss: 0.0059\n",
            "Epoch 987/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0036\n",
            "Epoch 988/1000\n",
            "160/160 [==============================] - 0s 63us/step - loss: 0.0037\n",
            "Epoch 989/1000\n",
            "160/160 [==============================] - 0s 64us/step - loss: 0.0038\n",
            "Epoch 990/1000\n",
            "160/160 [==============================] - 0s 60us/step - loss: 0.0030\n",
            "Epoch 991/1000\n",
            "160/160 [==============================] - 0s 71us/step - loss: 0.0031\n",
            "Epoch 992/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0084\n",
            "Epoch 993/1000\n",
            "160/160 [==============================] - 0s 62us/step - loss: 0.0141\n",
            "Epoch 994/1000\n",
            "160/160 [==============================] - 0s 66us/step - loss: 0.0040\n",
            "Epoch 995/1000\n",
            "160/160 [==============================] - 0s 78us/step - loss: 0.0058\n",
            "Epoch 996/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0033\n",
            "Epoch 997/1000\n",
            "160/160 [==============================] - 0s 101us/step - loss: 0.0088\n",
            "Epoch 998/1000\n",
            "160/160 [==============================] - 0s 85us/step - loss: 0.0050\n",
            "Epoch 999/1000\n",
            "160/160 [==============================] - 0s 79us/step - loss: 0.0058\n",
            "Epoch 1000/1000\n",
            "160/160 [==============================] - 0s 80us/step - loss: 0.0039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1VCsRF6SG9W",
        "colab_type": "text"
      },
      "source": [
        "Selanjutnya, kita akan lakukan prediksi terhadap angka lain diluar training data yaitu 26 dan akan membandingkan hasil prediksi seluruh training data dengan target.\n",
        "\n",
        "Kita bisa gunakan matplotlib untuk membuat dua grafik dan melihat perbandingannya. Line merah untuk target dan line biru untuk hasil prediksi."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLTPJTHwSdyA",
        "colab_type": "code",
        "outputId": "a242cb1d-7371-452c-ccef-af4ab97262be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Predict training data\n",
        "predict = model.predict(np.array([26]))\n",
        "print('f(26) = ', predict)\n",
        "\n",
        "predict_y = model.predict(train_x)\n",
        "\n",
        "# Draw target vs prediction\n",
        "plt.plot(train_x, train_y, 'r')\n",
        "plt.plot(train_x, predict_y, 'b')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('f(26) = ', array([[27.86055]], dtype=float32))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nha6UUj7i/5n4RfBNECEKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTYXW8TXVkz_",
        "colab_type": "text"
      },
      "source": [
        "Berapakah nilai hasil prediksi yang Anda peroleh? coba bandingkan dengan perhitungan manual!\n",
        "\n",
        "Sedangkan grafik prediction vs target untuk semua training data dapat dilihat sangat identik sekali."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TGnoK1_V2qv",
        "colab_type": "text"
      },
      "source": [
        "### Referensi\n",
        "\n",
        "https://medium.com/@samuelsena/pengenalan-deep-learning-part-4-deep-learning-framework-introduction-tensorflow-keras-b8f00b146f06"
      ]
    }
  ]
}